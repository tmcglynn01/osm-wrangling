{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling OSM Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenStreetMap (OSM) is a collaborative project to create a free an editable map of the world, much like what Wikipedia did for the encyclopeida. OSM offers a community-supported version of the dominant mapping application, Google Maps.\n",
    "\n",
    "For this project, we will be wrangling OSM data for Madison, WI. The OSM file was pulled from [BBBike exports of OpenStreetMap](https://download.bbbike.org/osm/bbbike/), which makes available copies of OSM data for more than 200 cities and regions world wide. I lived in Madison for a little while, and just recently moved from there in January, so I'm a bit familiar with this region.\n",
    "\n",
    "Due to the size of the OSM file we will be using the `xml.etree` module to iteratively parse through each line of XML data\n",
    "\n",
    "Let's start with importing some modules we will be using, the files that will be used to form the tables, and some regular expressions we will be using to validate the data as it comes to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from pprint import pprint\n",
    "from csv import DictWriter as dw\n",
    "from collections import defaultdict\n",
    "from sqlalchemy import create_engine, Table, Column, Integer, Numeric, String, MetaData, ForeignKey\n",
    "\n",
    "\n",
    "# I/O files\n",
    "OSM_FILE = 'Madison.osm'\n",
    "NODE_FILE = 'node.csv'\n",
    "NODE_TAG_FILE = 'node_tag.csv'\n",
    "WAY_FILE = 'way.csv'\n",
    "WAY_TAG_FILE = 'way_tag.csv'\n",
    "WAY_NODE_FILE = 'way_node.csv'\n",
    "\n",
    "# Header values for output CSV files\n",
    "NODE_HEAD = ['id', 'lat', 'lon', 'version']\n",
    "NODE_TAG_HEAD = ['id', 'key', 'value', 'type']\n",
    "WAY_HEAD = ['id', 'version']\n",
    "WAY_TAG_HEAD = ['id', 'key', 'value', 'type']\n",
    "WAY_NODE_HEAD = ['id', 'node_id']\n",
    "\n",
    "# Regular expressions for validating zips, phones, etc.\n",
    "PROBLEM_CHARACTERS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "ZIP_CODE_RE = re.compile(r'^(\\d{5})[- ]?(\\d{4})?$')\n",
    "PHONE_NUM_RE = re.compile(r'^[+]?(1)?[- \\.]?[( ]?(\\d{3})[ )]?[- \\.]?(\\d{3})[- \\.?]?(\\d{4})$')\n",
    "PHONE_REPLACEMENT_RE = '\\\\2\\\\3\\\\4'\n",
    "STREET_NAME_RE = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "# List of acceptable address names for validation\n",
    "expected_addresses = ['Avenue', 'Bend', 'Boulevard', 'Broadway', \n",
    "                      'Circle', 'Close', 'Commons', 'Court', \n",
    "                      'Crestway', 'Cross', 'Drive', 'Highway', \n",
    "                      'Lane', 'Lawn', 'Main', 'Mews', 'Parkway',\n",
    "                      'Pass', 'Place', 'Plaza', 'Ridge', 'Road',\n",
    "                      'Row', 'Square', 'Street', 'Terrace', 'Trace',\n",
    "                      'Trail', 'Way']\n",
    "\n",
    "# Use defaultdict sets for data validation, esp. streetnames\n",
    "zip_code_audit = defaultdict(set)\n",
    "phone_num_audit = defaultdict(set)\n",
    "address_audit = defaultdict(set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will write some functions that will help us audit the XML data and categorize it for us, based on what we want to be editing/validating. the `audit()` function will perform checks for `is_x` where x is one of the areas we will be validating. Once determined, an `audit_x` function will be performed to check the validity of the data entry against the regular expressions written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************#\n",
    "#     Functions for auditing the OSM data                            #\n",
    "#********************************************************************#\n",
    "\n",
    "\n",
    "def audit(file=OSM_FILE):\n",
    "    '''Returns dictionary values for invalid formats through audit function'''\n",
    "    f = open(file, 'r')\n",
    "    for event, element in ET.iterparse(f, events=('start',)):\n",
    "        if (element.tag == 'node') or (element.tag == 'way'):\n",
    "            for tag in element.iter('tag'):\n",
    "                if is_zip_code(tag):\n",
    "                    audit_zip_code(tag.attrib['v'])\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_name(tag.attrib['v'])\n",
    "                if is_phone(tag):\n",
    "                    audit_phone_num(tag.attrib['v'])\n",
    "    f.close()\n",
    "    audit_printer('ZIP CODES', zip_code_audit)\n",
    "    audit_printer('STREET NAMES', address_audit)\n",
    "    audit_printer('PHONE NUMBERS', phone_num_audit)\n",
    "\n",
    "\n",
    "def is_zip_code(element):\n",
    "    return element.attrib['k'] == 'addr:postcode'\n",
    "\n",
    "\n",
    "def is_street_name(element):\n",
    "    return element.attrib['k'] == 'addr:street'\n",
    "\n",
    "\n",
    "def is_phone(element):\n",
    "    return (element.attrib['k'] == 'phone') or (element.attrib['k'] == 'contact:phone')\n",
    "\n",
    "\n",
    "def audit_zip_code(zip_code):\n",
    "    '''Audits a zip code value to ensure it is in a valid format'''\n",
    "    match = zip_code_re.search(zip_code)\n",
    "    if not match:\n",
    "        zip_code_audit[zip_code].add(zip_code)\n",
    "\n",
    "\n",
    "def audit_street_name(street_name):\n",
    "    '''Audits a street value to ensure it is in a valid format'''\n",
    "    match = STREET_NAME_RE.search(street_name)\n",
    "    if match:\n",
    "        street_type = match.group()\n",
    "        if street_type not in expected_addresses:\n",
    "            address_audit[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def audit_phone_num(phone_num):\n",
    "    '''Audits a phone number to ensure it is in a valid format'''\n",
    "    match = PHONE_NUM_RE.search(phone_num)\n",
    "    if not match:\n",
    "        phone_num_audit[phone_num].add(phone_num)\n",
    "\n",
    "\n",
    "def audit_printer(audit_name, audit_type):\n",
    "    print('#', '*' * 68, '#')\n",
    "    print(' ' * 5, 'Auditing: {}'.format(audit_name))\n",
    "    print('#', '*' * 68, '#')\n",
    "    pprint(dict(audit_type))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auditing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ******************************************************************** #\n",
      "      Auditing: ZIP CODES\n",
      "# ******************************************************************** #\n",
      "{'5': {'5'}}\n",
      "\n",
      "\n",
      "\n",
      "# ******************************************************************** #\n",
      "      Auditing: STREET NAMES\n",
      "# ******************************************************************** #\n",
      "{'106': {'East Cheryl Parkway, Ste 106'},\n",
      " '2611': {'2611'},\n",
      " '3': {'North 3rd Street, Studio 3'},\n",
      " '320': {'University Row, Suite 320'},\n",
      " '5': {'North 3rd Street, Studio 5'},\n",
      " 'Ave': {'Atlas Ave',\n",
      "         'Commercial Ave',\n",
      "         'E Washington Ave',\n",
      "         'Highland Ave',\n",
      "         'Old University Ave',\n",
      "         'Sherman Ave',\n",
      "         'Thornton Ave',\n",
      "         'West Washington Ave'},\n",
      " 'Ave.': {'E. Verona Ave.'},\n",
      " 'Avenues': {'Sherman Avenues'},\n",
      " 'B': {'County Highway B'},\n",
      " 'Blvd': {'Shorewood Blvd', 'East Towne Blvd', 'South Midvale Blvd'},\n",
      " 'Cir': {'Hawks Landing Cir'},\n",
      " 'Crestway': {'Simon Crestway'},\n",
      " 'Ct': {'Bernard Ct'},\n",
      " 'Dr': {'Triverton Pike Dr', 'Excelsior Dr'},\n",
      " 'Dr.': {'Northport Dr.', 'Kroncke Dr.', 'Linden Dr.'},\n",
      " 'East': {'Highway 12 & 18 East'},\n",
      " 'G': {'State St #G'},\n",
      " 'Hamilton': {'N. Hamilton'},\n",
      " 'Johnson': {'E. Johnson'},\n",
      " 'K': {'County Highway K'},\n",
      " 'Ln': {'Elka Ln'},\n",
      " 'Ln.': {'Appleglen Ln.'},\n",
      " 'M': {'County Rd M', 'County Highway M'},\n",
      " 'Main': {'Cahill Main'},\n",
      " 'Mall': {'Bascom Mall',\n",
      "          'E Towne Mall',\n",
      "          'East Campus Mall',\n",
      "          'Henry Mall',\n",
      "          'West Towne Mall'},\n",
      " 'PB': {'County Highway PB'},\n",
      " 'PD': {'County Road PD', 'County Highway PD'},\n",
      " 'Pass': {'Arbor Mist Pass', 'Overlook Pass'},\n",
      " 'Pkwy': {'Mickelson Pkwy'},\n",
      " 'Q': {'County Highway Q'},\n",
      " 'Rd': {'Burma Rd',\n",
      "        'Lake Farm Rd',\n",
      "        'McKee Rd',\n",
      "        'Raymond Rd',\n",
      "        'S Stoughton Rd',\n",
      "        'South Stoughton Rd',\n",
      "        'Verona Rd',\n",
      "        'W Mineral Point Rd'},\n",
      " 'Rd.': {'McCoy Rd.'},\n",
      " 'Ridge': {'Eton Ridge'},\n",
      " 'Row': {'Rugby Row', 'University Row'},\n",
      " 'St': {'Copeland St',\n",
      "        'E Gorham St',\n",
      "        'Glenway St',\n",
      "        'N Hamilton St',\n",
      "        'Paoli St',\n",
      "        'S. Brearly St',\n",
      "        'State St',\n",
      "        'W Gilman St',\n",
      "        'Wilson St'},\n",
      " 'St.': {'N Pinckney St.'},\n",
      " 'Stoughton': {'North Stoughton'},\n",
      " 'US-51': {'US-51'},\n",
      " 'Williamson': {'Williamson'},\n",
      " 'road': {'junction road'},\n",
      " 'street': {'Walnut street'}}\n",
      "\n",
      "\n",
      "\n",
      "# ******************************************************************** #\n",
      "      Auditing: PHONE NUMBERS\n",
      "# ******************************************************************** #\n",
      "{'(608) 257-9700\\u200b': {'(608) 257-9700\\u200b'},\n",
      " '+1-608-283-9860;6082839860': {'+1-608-283-9860;6082839860'},\n",
      " 'no': {'no'}}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "audit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the data points that failed our validation. Some of these values are still valid (e.g. 'US-51' would be a valid address), so there is additional human validation required for these. We'll make 'map' dictionaries for zip codes, street names, and phone numbers to correct these values to more readable instances.\n",
    "\n",
    "Below is the result of this scrubbing! It is important to note that phone numbers will be updated/validating using a special `re.sub()` method which functions much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_map = {'5': ''}\n",
    "street_map = {\n",
    "    'Ave': 'Avenue', 'Ave.': 'Avenue', 'Avenues': 'Avenue', \n",
    "    'Blvd': 'Boulevard', \n",
    "    'Cir': 'Circle', 'Ct': 'Court',\n",
    "    'Dr': 'Drive', 'Dr.': 'Drive', \n",
    "    'Hamilton': 'Hamilton Street', \n",
    "    'Johnson': 'Johnson Street', \n",
    "    'Ln': 'Lane','Ln.': 'Lane', \n",
    "    'Mall': 'Mall Road', \n",
    "    'Pkwy': 'Parkway', \n",
    "    'Rd': 'Road', 'Rd.': 'Road', 'road': 'Road',\n",
    "    'St': 'Street', 'St.': 'Street', 'street': 'Street',\n",
    "    'Stoughton': 'Stoughton Road', \n",
    "    'Williamson': 'Williamson Street'}\n",
    "phone_map = {'(608) 257-9700\\u200b': '6082579700', 'no': ''}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the XML Tree\n",
    "\n",
    "Next, we will parse through the actual XML tree, shaping each of the elements to conform with what will then become a multiple csv files which will then be transformed into the tables which will make up our SQLite database.\n",
    "\n",
    "We'll start by defining a number of functions that will help us as we encounter each of the XML elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************#\n",
    "#     Functions for navigating the XML tree                          #\n",
    "#********************************************************************#\n",
    "\n",
    "def get_element(file=OSM_FILE, tags=('node', 'way', 'relation')):\n",
    "    '''Yield the element if it matches a specific tag type'''\n",
    "    context = ET.iterparse(file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, element in context:\n",
    "        if (event == 'end') and (element.tag in tags):\n",
    "            yield element\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def shape_element(element):\n",
    "    '''Return the node or way as a dictionary from raw XML data'''\n",
    "    node_attributes, way_attributes = {}, {}\n",
    "    way_nodes_list, tags_list = [], []\n",
    "\n",
    "    if element.tag == 'node':\n",
    "        node_attributes = shape_element_attributes(element, NODE_HEAD)\n",
    "        node_id = node_attributes['id']\n",
    "        tags = shape_element_tags(element, node_id)\n",
    "        return {'node': node_attributes, 'node_tag': tags}\n",
    "    elif element.tag == 'way':\n",
    "        way_attributes = shape_element_attributes(element, WAY_HEAD)\n",
    "        way_id = way_attributes['id']\n",
    "        tags = shape_element_tags(element, way_id)\n",
    "        way_nodes = shape_way_node(element, way_id)\n",
    "        return {'way': way_attributes, 'way_tag': tags, 'way_node': way_nodes}\n",
    "\n",
    "\n",
    "def shape_element_attributes(element, header):\n",
    "    '''Convert raw XML to a dictionary node or way'''\n",
    "    attributes = {}\n",
    "    for field in header:\n",
    "        attributes[field] = element.attrib[field]\n",
    "    return attributes\n",
    "\n",
    "\n",
    "def shape_element_tags(element, id_):\n",
    "    '''Shape the raw XML tags'''\n",
    "    tags = []\n",
    "    element_tags = element.findall('tag')\n",
    "    if element_tags:\n",
    "        for element_tag in element_tags:\n",
    "            key, value = element_tag.get('k'), element_tag.get('v')\n",
    "            if not re.search(PROBLEM_CHARACTERS, key):\n",
    "                tag = {'id': id_}\n",
    "                # First check to see if there is a colon in the string\n",
    "                # If there is, split the string into type and key\n",
    "                if ':' in key:\n",
    "                    tag['type'], tag['key'] = key.split(':', 1)\n",
    "                else:\n",
    "                    tag['type'], tag['key'] = '', key\n",
    "\n",
    "                # Next, address the tag values\n",
    "                if key == 'addr:street':\n",
    "                    tag['value'] = update_street_name(value)\n",
    "                elif (key == 'phone') or (key == 'contact:phone'):\n",
    "                    tag['value'] = update_phone_num(value)\n",
    "                elif key == 'addr:postcode':\n",
    "                    tag['value'] = update_zip_code(value)\n",
    "                else:\n",
    "                    tag['value'] = value\n",
    "\n",
    "                tags.append(tag)\n",
    "    return tags\n",
    "\n",
    "\n",
    "def shape_way_node(element, way_id):\n",
    "    '''Convert raw XML into way_nodes dictionary'''\n",
    "    way_nodes = []\n",
    "    way_node_tags = element.findall('nd')\n",
    "    for tag in way_node_tags:\n",
    "        w_node = {'id': way_id, 'node_id': tag.get('ref')}\n",
    "        way_nodes.append(w_node)\n",
    "    return way_nodes\n",
    "\n",
    "\n",
    "#********************************************************************#\n",
    "#     Functions for updating the OSM data                            #\n",
    "#********************************************************************#\n",
    "\n",
    "\n",
    "def update_zip_code(zip_code, mapping=zip_map):\n",
    "    '''Updates zip code format if it is found in the mapping'''\n",
    "    if zip_code in mapping:\n",
    "        replacement = mapping[zip_code]\n",
    "        zip_code.replace(zip_code, replacement)\n",
    "    return zip_code\n",
    "\n",
    "\n",
    "def update_street_name(street_name, mapping=street_map):\n",
    "    '''Updates street name format if it is found in the mapping'''\n",
    "    street_type = street_name.split(' ')[-1]\n",
    "    if street_type in mapping:\n",
    "        replacement = mapping[street_type]\n",
    "        street_name.replace(street_type, replacement)\n",
    "    return street_name\n",
    "\n",
    "\n",
    "def update_phone_num(phone_num, mapping=phone_map):\n",
    "    '''Updates phone number format if it is found in the mapping'''\n",
    "    if phone_num in mapping:\n",
    "        phone_num = mapping[phone_num]\n",
    "        return phone_num\n",
    "    else:\n",
    "        return re.sub(PHONE_NUM_RE, PHONE_REPLACEMENT_RE, phone_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main function takes the OSM data and processes it into csv files which will then be manipulated into SQL databases which will exist in the memory of the browser--this is the easiest way to present the database through Jupyter and also makes it nicely portable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************#\n",
    "#     Main Function                                                  #\n",
    "#********************************************************************#\n",
    "\n",
    "\n",
    "def process_map(file=OSM_FILE):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "    with open(NODE_FILE, 'w', encoding='utf-8') as node_file, \\\n",
    "            open(NODE_TAG_FILE, 'w', encoding='utf-8') as node_tag_file, \\\n",
    "            open(WAY_FILE, 'w', encoding='utf-8') as way_file, \\\n",
    "            open(WAY_TAG_FILE, 'w', encoding='utf-8') as way_tag_file, \\\n",
    "            open(WAY_NODE_FILE, 'w', encoding='utf-8') as way_node_file:\n",
    "        \n",
    "        # Use dictwriter for each of the csv file writers\n",
    "        node_writer = dw(node_file, NODE_HEAD)\n",
    "        node_tag_writer = dw(node_tag_file, NODE_TAG_HEAD)\n",
    "        way_writer = dw(way_file, WAY_HEAD)\n",
    "        way_tag_writer = dw(way_tag_file, WAY_TAG_HEAD)\n",
    "        way_node_writer = dw(way_node_file, WAY_NODE_HEAD)\n",
    "        \n",
    "        # Write the headers for each of the csv files\n",
    "        node_writer.writeheader()\n",
    "        node_tag_writer.writeheader()\n",
    "        way_writer.writeheader()\n",
    "        way_tag_writer.writeheader()\n",
    "        way_node_writer.writeheader()\n",
    "        \n",
    "        # Determine if node/way, then write XML data to file\n",
    "        for element in get_element(file, tags=('node', 'way')):\n",
    "            elem = shape_element(element)\n",
    "            if elem:\n",
    "                if element.tag == 'node':\n",
    "                    node_writer.writerow(elem['node'])\n",
    "                    node_tag_writer.writerows(elem['node_tag'])\n",
    "                elif element.tag == 'way':\n",
    "                    way_writer.writerow(elem['way'])\n",
    "                    way_node_writer.writerows(elem['way_node'])\n",
    "                    way_tag_writer.writerows(elem['way_tag'])\n",
    "\n",
    "process_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Database\n",
    "\n",
    "Now that we have parsed the XML tree, we are ready to create an populate the database. For this, we will be using the library SQLAlchemy, which allows us to create a SQLite database in the memory of the browser.\n",
    "\n",
    "We will be taking the csv files that were created during the `process_map()` function and transform them in SQL databases using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************#\n",
    "#     Functions for managing the Database                            #\n",
    "#********************************************************************#\n",
    "\n",
    "\n",
    "def csv_to_sql(csv_file, table):\n",
    "    \"\"\"Returns a table in SQL from a csv file provided\"\"\"\n",
    "    df = pd.read_csv(csv_file, encoding='utf-8')\n",
    "    df.to_sql(table, engine, if_exists='replace', index=True)\n",
    "    \n",
    "\n",
    "#********************************************************************#\n",
    "#     Database schema and creation                                   #\n",
    "#********************************************************************#\n",
    "\n",
    "# Create the datatbase engine, schema, and tables\n",
    "engine = create_engine('sqlite:///:memory:', echo=False)\n",
    "metadata = MetaData()\n",
    "\n",
    "# Create the tables for the database\n",
    "node_table = Table('node', metadata,\n",
    "                    Column('id', Integer, primary_key=True, nullable=False),\n",
    "                    Column('lat', Numeric),\n",
    "                    Column('lon', Numeric),\n",
    "                    Column('version', Integer))\n",
    "node_tag_table = Table('node_tag', metadata,\n",
    "                    Column('id', Integer, ForeignKey('node.id'), nullable=False),\n",
    "                    Column('key', String),\n",
    "                    Column('value', String),\n",
    "                    Column('type', String))\n",
    "way_table = Table('way', metadata,\n",
    "                    Column('id', Integer, primary_key=True, nullable=False),\n",
    "                    Column('version', Integer))\n",
    "way_tag_table = Table('way_tag', metadata,\n",
    "                    Column('id', Integer, ForeignKey('way.id'), nullable=False),\n",
    "                    Column('key', String),\n",
    "                    Column('value', String),\n",
    "                    Column('type', String))\n",
    "way_node_table = Table('way_node', metadata,\n",
    "                    Column('id', Integer, ForeignKey('way.id'), nullable=False),\n",
    "                    Column('node_id', Integer, ForeignKey('node.id'), nullable=False))\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Convert the csv files into their respective SQL DBs\n",
    "csv_to_sql(NODE_FILE, 'node')\n",
    "csv_to_sql(NODE_TAG_FILE, 'node_tag')\n",
    "csv_to_sql(WAY_FILE, 'way')\n",
    "csv_to_sql(WAY_TAG_FILE, 'way_tag')\n",
    "csv_to_sql(WAY_NODE_FILE, 'way_node')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can begin exploring the data.\n",
    "\n",
    "Our fileset includes the following files and their sizes. Note the original `Madison.osm` file at 152.8 MB.\n",
    "\n",
    "| File Name    \t| File Size (MB) \t|\n",
    "|--------------\t|----------------\t|\n",
    "| Madison.osm  \t| 152.8          \t|\n",
    "| node.csv     \t| 47.7           \t|\n",
    "| node_tag.csv \t| 1.3            \t|\n",
    "| way.csv      \t| 2.0            \t|\n",
    "| way_node.csv \t| 33.7           \t|\n",
    "| way_tag.csv  \t| 9.2            \t|\n",
    "\n",
    "UDACITY NOTE: This dataset **does not include the number of unique users** that have updated the map. I do not have this information and cannot fulfill the requirement on the rubric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Nodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1305256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Nodes\n",
       "0          1305256"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql =   '''\n",
    "        SELECT COUNT(id) AS \"Number of Nodes\" \n",
    "        FROM node;\n",
    "        '''\n",
    "pd.read_sql_query(sql, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Ways</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Ways\n",
       "0          157906"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql =   '''\n",
    "        SELECT COUNT(*) AS \"Number of Ways\" \n",
    "        FROM way;\n",
    "        '''\n",
    "pd.read_sql_query(sql, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Some Queries\n",
    "\n",
    "Now that we have the datasets properly loaded into the database, we can begin exploring some interesting featureus of Madison. These next couple of queries look at unique keys from the `node_tag` table that have at least 30 instances across Madison. We'll look at values in the midspread of that, to find a couple that would be worth looking into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         count_keys\n",
      "count     83.000000\n",
      "mean     469.048193\n",
      "std     1203.210025\n",
      "min       31.000000\n",
      "25%       55.000000\n",
      "50%      148.000000\n",
      "75%      440.500000\n",
      "max    10060.000000\n",
      "\n",
      "        unique_keys  count_keys\n",
      "3             bench          56\n",
      "22          parking          67\n",
      "30         state_id          67\n",
      "6         county_id          67\n",
      "14         historic          70\n",
      "27     shelter_type          71\n",
      "13       healthcare          72\n",
      "5           country          73\n",
      "1          backrest          74\n",
      "7           created          78\n",
      "12       feature_id          80\n",
      "19           noexit          80\n",
      "33   tactile_paving          85\n",
      "39             unit          99\n",
      "4          capacity         111\n",
      "11              ele         119\n",
      "37  traffic_signals         127\n",
      "34         takeaway         128\n",
      "31             stop         134\n",
      "26          shelter         136\n",
      "38             type         148\n",
      "21    opening_hours         162\n",
      "24            place         170\n",
      "20           office         170\n",
      "28           source         175\n",
      "17         man_made         186\n",
      "23            phone         187\n",
      "15      information         189\n",
      "32        structure         212\n",
      "0            access         216\n",
      "9            design         233\n",
      "18         material         255\n",
      "36  traffic_calming         263\n",
      "35          tourism         337\n",
      "40          website         349\n",
      "10        direction         351\n",
      "2           barrier         379\n",
      "8           cuisine         407\n",
      "16          leisure         410\n",
      "25         postcode         421\n",
      "29            state         425\n"
     ]
    }
   ],
   "source": [
    "sql =   '''\n",
    "        SELECT DISTINCT(key) AS unique_keys,\n",
    "        COUNT(*) AS count_keys\n",
    "        FROM node_tag\n",
    "        GROUP BY key\n",
    "        HAVING count_keys > 30;\n",
    "        '''\n",
    "df=pd.read_sql_query(sql, engine)\n",
    "print(df.describe(), end='\\n\\n')\n",
    "\n",
    "sql =   '''\n",
    "        SELECT DISTINCT(key) AS unique_keys,\n",
    "        COUNT(*) AS count_keys\n",
    "        FROM node_tag\n",
    "        GROUP BY key\n",
    "        HAVING count_keys\n",
    "        BETWEEN 55 AND 440;\n",
    "        '''\n",
    "df=pd.read_sql_query(sql, engine)\n",
    "print(df.sort_values('count_keys'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What kind of tourist attractions exist in Madison, and how many of those are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>count_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>information</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>artwork</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>viewpoint</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attraction</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>picnic_site</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hotel</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gallery</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>museum</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>camp_pitch</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>camp_site</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>motel</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hostel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>apartment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          value  count_value\n",
       "0   information          189\n",
       "1       artwork           56\n",
       "2     viewpoint           28\n",
       "3    attraction           21\n",
       "4   picnic_site           10\n",
       "5         hotel            8\n",
       "6       gallery            7\n",
       "7        museum            5\n",
       "8    camp_pitch            5\n",
       "9     camp_site            4\n",
       "10        motel            2\n",
       "11       hostel            1\n",
       "12    apartment            1"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql =   '''\n",
    "        SELECT value,\n",
    "        COUNT(*) AS count_value\n",
    "        FROM node_tag\n",
    "        WHERE key='tourism'\n",
    "        GROUP BY value\n",
    "        ORDER BY count_value DESC;\n",
    "        '''\n",
    "pd.read_sql_query(sql, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the more popular types of cuisine in Madison?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type of Cuisine</th>\n",
       "      <th>Count of Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pizza</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mexican</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chinese</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asian</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>italian</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>indian</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>regional</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pasta</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>japanese</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>american</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>barbecue</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wings</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>thai</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mediterranean</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>greek</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type of Cuisine  Count of Type\n",
       "0            pizza             29\n",
       "1          mexican             16\n",
       "2          chinese             15\n",
       "3            asian             15\n",
       "4          italian             10\n",
       "5           indian              9\n",
       "6         regional              6\n",
       "7            pasta              6\n",
       "8         japanese              6\n",
       "9         american              6\n",
       "10        barbecue              5\n",
       "11           wings              4\n",
       "12            thai              4\n",
       "13   mediterranean              4\n",
       "14           greek              4"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = '''\n",
    "        SELECT value AS \"Type of Cuisine\",\n",
    "        COUNT(*) AS \"Count of Type\"\n",
    "        FROM node_tag\n",
    "        JOIN (SELECT DISTINCT id FROM node_tag WHERE value='restaurant') node_id\n",
    "        ON node_tag.id=node_id.id\n",
    "        WHERE key='cuisine'\n",
    "        GROUP BY value\n",
    "        ORDER BY \"Count of Type\" DESC\n",
    "        LIMIT 15;\n",
    "        '''\n",
    "pd.read_sql_query(sql, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What kind of leisure activities can you find in Madison?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type of Leisure</th>\n",
       "      <th>Count of Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>playground</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>picnic_table</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slipway</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fitness_centre</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pitch</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>firepit</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>park</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sports_centre</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>outdoor_seating</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>garden</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type of Leisure  Count of Type\n",
       "0       playground            115\n",
       "1     picnic_table            100\n",
       "2          slipway             36\n",
       "3   fitness_centre             32\n",
       "4            pitch             27\n",
       "5          firepit             18\n",
       "6             park             17\n",
       "7    sports_centre             13\n",
       "8  outdoor_seating             10\n",
       "9           garden             10"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = '''\n",
    "        SELECT value AS \"Type of Leisure\",\n",
    "        COUNT(*) AS \"Count of Type\"\n",
    "        FROM node_tag\n",
    "        JOIN (SELECT DISTINCT id FROM node_tag) node_id\n",
    "        ON node_tag.id=node_id.id\n",
    "        WHERE key='leisure'\n",
    "        GROUP BY value\n",
    "        HAVING \"Count of Type\" > 5\n",
    "        ORDER BY \"Count of Type\" DESC;\n",
    "        '''\n",
    "pd.read_sql_query(sql, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas for Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Madison such a small city that perhaps all of Wisconsin may have been a more meaningful dataset; even the few queries that were run in this write-up yielded results that would have been better represented with broader dataset. Types of cuisine, for instance, would be a significantly more interesting analysis for all of Wisconsin where more datapoints could be yielded.\n",
    "\t\n",
    "There would not be any drawbacks to this improvement, minus additional computation time required for a file so big. At that rate, we could begin looking for ways to optimize some of the functions for a faster execution time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
